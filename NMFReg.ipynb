{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Negative Matrix Factorization (NMF)\n",
    "Performs NMF on slide-seq data to assign beads to cell types based on single-cell data. <br>\n",
    "7/28/19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#packages\n",
    "import argparse \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import display\n",
    "import scipy.optimize\n",
    "import scipy.stats\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.decomposition import NMF\n",
    "from tqdm import tqdm\n",
    "from matplotlib import colors\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot settings\n",
    "%pylab inline\n",
    "rcParams['axes.spines.right'] = False\n",
    "rcParams['axes.spines.top'] = False\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams['figure.facecolor']='white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block creates parser to interpret command line info and make arguments into variables. \n",
    "parser = argparse.ArgumentParser(description = \"handle inputs from sam matlab script to run NMFreg on puck data\")\n",
    "parser.add_argument(\"-da\", type=str,\n",
    "                   help = \"Pass the data path for the atlas here\")\n",
    "parser.add_argument(\"-dp\", type=str,\n",
    "                   help = \"Pass the data path for the puck here\")\n",
    "parser.add_argument(\"-t\", type=str,\n",
    "                   help = \"string of tissue type as is in data reference directory eg hippocampus, cerebellum, etc\")\n",
    "parser.add_argument(\"-c\", type=int,\n",
    "                   help = \"cutoff for the UMI filtering of the DGE for the puck\")\n",
    "parser.add_argument(\"-dge\", type=str,\n",
    "                   help = \"name of the dge file. No extension assumes csv\")\n",
    "parser.add_argument(\"-bl\", type=str,\n",
    "                   help = \"name of the bead location file passed here. No extension assumes csv\")\n",
    "parser.add_argument(\"-s\", type=str,\n",
    "                   help = \"health status of tissue (WT/DKD)\")\n",
    "parser.add_argument(\"-pkn\", type=str,\n",
    "                   help = \"puck number\")\n",
    "\n",
    "print(parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the block below, you may change the following for your data:\n",
    "-da   : to file path for your single cell data <br>\n",
    " -dp  : to file path for your puck data<br>\n",
    " -t   : to the type of tissue you are observing<br>\n",
    " -c   : to your preferred UMI cutoff value<br>\n",
    " -dge : to the file path for your DGE file<br>\n",
    " -bl  : to the file path for your bead location file<br>\n",
    " -s   : to the status of the tissue you are working with (for kidney, DKD or WT)<br>\n",
    " -pkn : to the puck number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Block utilizes parser\n",
    "args = parser.parse_args('-da /broad/macosko/bstickels/data/slideseq/slideseq/NMFreg -dp /broad/thechenlab/Jamie/Kidney/Puck_181206_3 -t kidney_ob -c 5 -dge MappedDGEForR -bl BeadLocationsForR -s DKD -pkn Puck_181206_3'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the block below, you may change the following for your own data:\n",
    "NMFReg_output: to your filepath for plot ouput<br>\n",
    "Perm_test_output: to your filepath for permutation test data<br>\n",
    "Interactive_plot_output: to your filepath for creating interactive plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize file path for output of data\n",
    "NMFreg_output = \"/broad/thechenlab/breanna/NMFReg_output/\"\n",
    "if not os.path.exists(NMFreg_output):\n",
    "   os.makedirs(NMFreg_output)\n",
    "Perm_test_output = \"/broad/thechenlab/breanna/permutation_test_data/\"\n",
    "if not os.path.exists(Perm_test_output):\n",
    "   os.makedirs(Perm_test_output)\n",
    "Interactive_plot_output = \"/broad/thechenlab/breanna/interactive_plot_data/\"\n",
    "if not os.path.exists(Interactive_plot_output):\n",
    "   os.makedirs(Interactive_plot_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Block formalizes variables from parser info\n",
    "\n",
    "# Create variables from parser input\n",
    "#atlas data_path\n",
    "data_path = args.da\n",
    "\n",
    "#puck data path\n",
    "data_path_puck = args.dp\n",
    "\n",
    "tissue_name = args.t\n",
    "\n",
    "#UMI threshold for the cutoff\n",
    "UMI_threshold = args.c\n",
    "\n",
    "puck_dge_name = args.dge\n",
    "\n",
    "bead_locations = args.bl\n",
    "tissue_data_path = \"{}/{}\".format(data_path,tissue_name) \n",
    "\n",
    "tissue_status=args.s\n",
    "\n",
    "pkn=args.pkn\n",
    "\n",
    "#if not os.path.exists(tissue_data_path):\n",
    "#\tos.makedirs(tissue_data_path)\n",
    "print(bead_locations)\n",
    "print(puck_dge_name)\n",
    "print(data_path)\n",
    "print(data_path_puck)\n",
    "print(tissue_name)\n",
    "print(UMI_threshold)\n",
    "print(tissue_data_path)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for saving figures\n",
    "def save_result(name):\n",
    "    plt.savefig(\"{}plots/{}.eps\".format(NMFreg_output, name),\n",
    "                bbox_inches='tight', transparent=True, dpi=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in count and coordinate data\n",
    "dge_path = \"{}/{}.csv\".format(data_path_puck,puck_dge_name)\n",
    "dge = pd.read_csv(dge_path, header = 0, index_col = 0)\n",
    "dge = dge.T\n",
    "dge = dge.reset_index()\n",
    "dge = dge.rename(columns={'index':'barcode'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Save in the locations of each bead\n",
    "coords = pd.read_csv(\"{}/{}.csv\".format(data_path_puck,bead_locations), header = 0)\n",
    "coords = coords.rename(columns={'Barcodes':'barcode'})\n",
    "coords = coords.rename(columns={'barcodes':'barcode'})\n",
    "df_merged = dge.merge(coords, right_on='barcode', left_on='barcode')\n",
    "counts = df_merged.drop(['xcoord', 'ycoord'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in atlas (single-cell) data \n",
    "atlas_dge = pd.read_csv(\"{}/dge_hvgs.csv\".format(tissue_data_path), index_col = 0, header = 0)\n",
    "atlas_dge = atlas_dge.T \n",
    "cell_clusters = pd.read_csv(\"{}/cell_cluster_outcome.csv\".format(tissue_data_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Intersect gene lists for atlas and puck data sets, create new dataframe with only those genes\n",
    "atlas_genes = atlas_dge.columns.tolist()\n",
    "puck_genes = counts.columns.tolist()[1:]#1 to skip first column (barcode)\n",
    "gene_intersection = list(set(atlas_genes) & set(puck_genes))#return a list of only genes that appear in both atlas and puck genes\n",
    "atlasdge = atlas_dge[gene_intersection] #filters out gene expressions if not present in both slide-seq and atlas data\n",
    "\n",
    "puckcounts = counts[['barcode'] + gene_intersection]\n",
    "puckcounts = puckcounts.set_index(counts['barcode'])\n",
    "puckcounts = puckcounts.drop('barcode', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots spatial loction of beads and number of gene expressions per bead\n",
    "sample_info = df_merged[['barcode','xcoord', 'ycoord']]\n",
    "UMIspergene = np.sum(puckcounts, axis=0)#compute the number of UMIs per gene\n",
    "gr0_UMIspergene = UMIspergene[0:][UMIspergene[0:] > 0]#filters genes with 0 UMIs\n",
    "counts_gr0 = counts[['barcode'] + gr0_UMIspergene.index.tolist()]\n",
    "counts_gr0_barcodestotals = np.sum(counts_gr0.drop('barcode', axis=1), axis=1)\n",
    "sample_info['total_counts'] = counts_gr0_barcodestotals\n",
    "sample_info_grthreshold = sample_info.loc[sample_info['total_counts'] > UMI_threshold]\n",
    "coords = sample_info_grthreshold\n",
    "coords = coords.reset_index(drop=True) #reset indices after filtering\n",
    "df_merged_grthreshold = counts_gr0.merge(sample_info_grthreshold, right_on='barcode', left_on='barcode')\n",
    "counts_gr0_grthreshold = df_merged_grthreshold.drop(['xcoord', 'ycoord', 'total_counts'], axis=1)\n",
    "counts = counts_gr0_grthreshold\n",
    "df_merged_grthreshold = []\n",
    "counts_gr0 = []\n",
    "counts_gr0_grthreshold = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot count/coordinate data\n",
    "\n",
    "#Plot location of data\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.scatter(coords['xcoord'], coords['ycoord'], c='k', s=4, alpha=0.6);\n",
    "plt.axis('equal');\n",
    "plt.show()\n",
    "#save_result(\"filtered_tissue_coverage\")\n",
    "plt.close()\n",
    "\n",
    "#Plot number of genes expressed per bead\n",
    "plt.figure(figsize = (12, 12))\n",
    "plt.set_cmap('viridis_r')\n",
    "plt.scatter(coords['xcoord'], coords['ycoord'], c=coords['total_counts'], s=4, alpha=0.6);\n",
    "plt.axis('equal');\n",
    "plt.colorbar();\n",
    "plt.show()\n",
    "#save_result(\"bead_counts\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Intersect gene lists for atlas and puck data sets after filter 2 blocks above \n",
    "atlas_genes = atlas_dge.columns.tolist()\n",
    "puck_genes = counts.columns.tolist()[1:]#1 to skip first column (barcode)\n",
    "gene_intersection = list(set(atlas_genes) & set(puck_genes))#return a list of only genes that appear in both atlas and puck genes\n",
    "atlasdge = atlas_dge[gene_intersection]#filters out gene expressions if not present in both slide-seq and atlas data\n",
    "\n",
    "pcounts = counts[['barcode'] + gene_intersection]\n",
    "pcounts = pcounts.set_index(counts['barcode'])\n",
    "pcounts = pcounts.drop('barcode', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Normalize UMI count in each bead\n",
    "cell_totalUMI = np.sum(pcounts, axis = 1)#sum along rows\n",
    "pcounts_cellnorm = np.true_divide(pcounts, cell_totalUMI[:,None])#normalize per total umi count\n",
    "pcounts_scaled = StandardScaler(with_mean=False).fit_transform(pcounts_cellnorm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#same as above for atlas data\n",
    "cell_totalUMIa = np.sum(atlasdge, axis = 1)\n",
    "atlasdge_cellnorm = np.true_divide(atlasdge, cell_totalUMIa[:,None])\n",
    "atlasdge_scaled = StandardScaler(with_mean=False).fit_transform(atlasdge_cellnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observe how many cells are assigned to the clusters (from file)\n",
    "cell_clusters.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Perform NMF on the atlas data to find basis for projection\n",
    "#NMF allows us to quantify how likely that a bead is a certain cell type (in the case of a bead being multiple cells,\n",
    "#NMF tells how much each cell type contributed to a given bead)\n",
    "\n",
    "K = 23 #Want k to be larger than the number of clusters but smaller than the number of cells for reduced dimensionality\n",
    "alpha = 0\n",
    "l1_ratio = 0\n",
    "random_state = 17\n",
    "model = NMF(n_components=K, init='random', random_state = random_state, alpha = alpha, l1_ratio = l1_ratio)\n",
    "\n",
    "# Decomposed matrixes\n",
    "Ha = model.fit_transform(atlasdge_scaled)#weights\n",
    "Wa = model.components_ #basis vectors\n",
    "\n",
    "Ha_norm = StandardScaler(with_mean=False).fit_transform(Ha)\n",
    "Ha_norm = pd.DataFrame(Ha_norm)\n",
    "Ha_norm['barcode'] = atlasdge.index.tolist()\n",
    "    \n",
    "\n",
    "maxloc = Ha_norm.drop('barcode', axis=1).values.argmax(axis=1)#location of maximum gene expression in each row\n",
    "cell_clusters['maxloc'] = maxloc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign cell types to each factor from NMF\n",
    "#plots telling how much each cluster type goes into each component (linear combinations)\n",
    "\n",
    "num_atlas_clusters = max(cell_clusters['cluster'])+1\n",
    "bins_n = num_atlas_clusters\n",
    "factor_to_celltype_df = pd.DataFrame(0, index=range(0, num_atlas_clusters), columns=range(K))\n",
    "\n",
    "#plot how much each cell type contributes to a factor\n",
    "for k in range(K):\n",
    "    print (\"cell type assignment for {0} th cluster\".format(k))\n",
    "    n, bins, patches = plt.hist(cell_clusters['cluster'][cell_clusters['maxloc'] == k],\n",
    "            bins_n, range = (-0.5,(bins_n)-.5), facecolor='green', alpha=0.75)\n",
    "    plt.xticks(np.arange(20))\n",
    "    plt.show()\n",
    "    factor_to_celltype_df[k] = n.astype(int)\n",
    "    print(n)\n",
    "    print(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates a heatmap (using hierarchichal clustering)\n",
    "factor_to_celltype_df = factor_to_celltype_df.T\n",
    "\n",
    "factor_total = np.sum(factor_to_celltype_df, axis = 1)#sum of weights for each factor\n",
    "\n",
    "factor_to_celltype_df_norm = np.true_divide(factor_to_celltype_df, factor_total[:,None])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "cx = sns.clustermap(factor_to_celltype_df_norm, fmt = 'd',\n",
    "                cmap=\"magma_r\", linewidth=0.5, col_cluster = False,\n",
    "                   figsize=(10, 15))\n",
    "ax = sns.clustermap(factor_to_celltype_df_norm, fmt = 'd',\n",
    "                cmap=\"magma_r\", linewidth=0.5, col_cluster = False,\n",
    "                   annot = factor_to_celltype_df.loc[cx.dendrogram_row.reordered_ind],\n",
    "                   figsize=(10, 20))\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "factor_total = np.sum(factor_to_celltype_df, axis = 1)\n",
    "factor_to_celltype_df_norm = np.true_divide(factor_to_celltype_df, factor_total[:,None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create factor to cell type and cell type to factor dictionaries\n",
    "maxloc_fc = factor_to_celltype_df.values.argmax(axis=1)\n",
    "factor_to_celltype_dict = {factor : ctype for factor, ctype in enumerate(maxloc_fc)}\n",
    "\n",
    "celltype_to_factor_dict = {}\n",
    "for c in range(0, num_atlas_clusters):\n",
    "    celltype_to_factor_dict[c] = [k for k, v in factor_to_celltype_dict.items() if v == c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Assign each bead a to a cell type\n",
    "\n",
    "#Perform NNLS with the atlas basis\n",
    "WaT = Wa.T\n",
    "XsT = pcounts_scaled.T\n",
    "\n",
    "Hs_hat = []\n",
    "for b in tqdm(range(XsT.shape[1])):\n",
    "    h_hat = scipy.optimize.nnls(WaT, XsT[:, b])[0]\n",
    "    if b == 0:\n",
    "        Hs_hat = h_hat\n",
    "    else:\n",
    "        Hs_hat = np.vstack((Hs_hat, h_hat))\n",
    "\n",
    "Ha = pd.DataFrame(Ha)\n",
    "Ha['cellname'] = atlasdge.index.tolist()\n",
    "Ha_indexed = Ha.set_index('cellname')\n",
    "\n",
    "Hs = pd.DataFrame(Hs_hat)\n",
    "Hs['barcode'] = pcounts.index.tolist()\n",
    "Hs_indexed = Hs.set_index('barcode')\n",
    "\n",
    "Hs_indexed.to_csv(\"{}Hs{}_{}_{}_{}.csv\".format(NMFreg_output, K, alpha, l1_ratio, random_state), index=True)\n",
    "\n",
    "#Scale the Ha and Hs matrices to unit variance\n",
    "Ha_norm = pd.DataFrame(StandardScaler(with_mean=False).fit_transform(Ha_indexed))\n",
    "Hs_norm = pd.DataFrame(StandardScaler(with_mean=False).fit_transform(Hs_indexed))\n",
    "\n",
    "#Re-add indices after scaling\n",
    "Ha_norm['cellname'] = atlasdge.index.tolist()\n",
    "Ha_norm_indexed = Ha_norm.set_index('cellname')\n",
    "Hs_norm['barcode'] = pcounts.index.tolist()\n",
    "Hs_norm_indexed = Hs_norm.set_index('barcode')\n",
    "\n",
    "#Assign barcodes a cluster assignment from the atlas data set based on max factors\n",
    "maxloc_s = Hs_norm_indexed.values.argmax(axis=1)\n",
    "barcode_clusters = pd.DataFrame()\n",
    "barcode_clusters['barcode'] = Hs_norm_indexed.index.tolist()\n",
    "barcode_clusters['max_factor'] = maxloc_s\n",
    "barcode_clusters['atlas_cluster'] = barcode_clusters['barcode']\n",
    "\n",
    "\n",
    "for c in range(0, num_atlas_clusters):\n",
    "    condition = np.in1d(barcode_clusters['max_factor'], celltype_to_factor_dict[c])\n",
    "    barcode_clusters['atlas_cluster'][condition] = c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of times that celltype is the max factor\n",
    "barcode_clusters['atlas_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the assignments onto the puck\n",
    "for i in range(0,num_atlas_clusters):\n",
    "    boolcol = (barcode_clusters['atlas_cluster']==i)\n",
    "    sub_df = barcode_clusters.copy()\n",
    "    sub_df['bool'] = boolcol\n",
    "    plt.figure(figsize =(10, 10))\n",
    "    plt.set_cmap('nipy_spectral_r')\n",
    "    plt.scatter(coords['xcoord'], coords['ycoord'], c=sub_df['bool'], marker = 's', s = 720/1000,alpha=0.6)\n",
    "    plt.title(tissue_name + ' atlas cluster' + str(i))\n",
    "    plt.rc('xtick', labelsize=30)     \n",
    "    plt.rc('ytick', labelsize=30)\n",
    "    plt.xlabel('x (x1e3)',fontsize=32)\n",
    "    plt.ylabel('y (x1e3)',fontsize=32)\n",
    "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "    plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    plt.axis('equal')  \n",
    "    #plt.savefig(\"c5_Puck_181206_3.svg\",format=\"svg\")\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combining factor contributions into cell type columns via l2 norm\n",
    "def deconv_factor_to_celltype(row, adict, K=K, nc = num_atlas_clusters):\n",
    "    tmp_list = [0]*nc\n",
    "    for key in range(K):\n",
    "        item = adict[key]\n",
    "        tmp_list[item] += row[key]**2\n",
    "    return pd.Series(np.sqrt(tmp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#based on the cell types in each factor, we get how much of each cell type is being expressed in each bead\n",
    "bead_deconv_df = Hs_norm.apply(lambda x: deconv_factor_to_celltype(row=x, adict=factor_to_celltype_dict), axis = 1)\n",
    "bead_deconv_df.insert(0, 'barcode', Hs_norm['barcode'])\n",
    "bead_deconv_df.columns = ['barcode'] + (bead_deconv_df.columns[1:]).tolist()\n",
    "bead_deconv_df = pd.DataFrame(bead_deconv_df) \n",
    "maxloc_ct = bead_deconv_df.drop('barcode', axis=1).values.argmax(axis=1)\n",
    "bead_maxct_df = pd.DataFrame()\n",
    "bead_maxct_df['barcode'] = bead_deconv_df['barcode']\n",
    "bead_maxct_df['max_cell_type'] = maxloc_ct\n",
    "bead_maxct_df = pd.DataFrame()\n",
    "bead_maxct_df['barcode'] = bead_deconv_df['barcode']\n",
    "bead_maxct_df['max_cell_type'] = maxloc_ct#choosing the max value so that we get the most likely type that cell is in the bead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = collections.Counter(factor_to_celltype_dict.values())\n",
    "co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "celltype_dict = {x: x for x in range(0,num_atlas_clusters)}\n",
    "metacell_dict = celltype_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#different deconvolution methods (get cell type info from factors)\n",
    "def deconv_factor_to_celltype_sum(row, adict, K=K, nc=num_atlas_clusters):\n",
    "    tmp_list = [0]*nc\n",
    "    for key in range(K):\n",
    "        item = adict[key]\n",
    "        tmp_list[item] += row[key]\n",
    "    return pd.Series(tmp_list)\n",
    "\n",
    "def deconv_factor_to_celltype_l2(row, adict, K=K, nc=num_atlas_clusters):\n",
    "    tmp_list = [0]*nc\n",
    "    for key in range(K):\n",
    "        item = adict[key]\n",
    "        tmp_list[item] += row[key]**2\n",
    "    return pd.Series(np.sqrt(tmp_list))\n",
    "\n",
    "#mean broken because of collections, probably. inconsistent matrix size?\n",
    "def deconv_factor_to_celltype_mean(row, adict, K=K, nc=num_atlas_clusters):\n",
    "    tmp_list = [0]*nc\n",
    "    for key in range(K):\n",
    "        item = adict[key]\n",
    "        tmp_list[item] += row[key]\n",
    "    num_fact = list(collections.OrderedDict(sorted(collections.Counter(adict.values()).items())).values()) \n",
    "    mean_tmp_list = np.divide(tmp_list, num_fact)\n",
    "    return pd.Series(mean_tmp_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#choosing which way to deconvolute cell info from factors\n",
    "def cell_deconv(collapse):\n",
    "    \n",
    "    if(collapse=='l2'):\n",
    "        tmp_df = Ha_norm.drop('cellname', axis=1).apply(lambda x: deconv_factor_to_celltype_l2(row=x, adict=factor_to_celltype_dict), axis = 1)\n",
    "    \n",
    "    if(collapse=='sum'):\n",
    "        tmp_df = Ha_norm.drop('cellname', axis=1).apply(lambda x: deconv_factor_to_celltype_sum(row=x, adict=factor_to_celltype_dict), axis = 1)\n",
    "    \n",
    "    if(collapse=='mean'):\n",
    "        tmp_df = Ha_norm.drop('cellname', axis=1).apply(lambda x: deconv_factor_to_celltype_mean(row=x, adict=factor_to_celltype_dict), axis = 1)\n",
    "    \n",
    "    tmp_df.insert(0, 'cellname', Ha_norm['cellname'])\n",
    "    tmp_df.columns = ['cellname'] + (tmp_df.columns[1:]).tolist()\n",
    "    print(tmp_df.columns)\n",
    "    tmp_df = pd.DataFrame(tmp_df)\n",
    "    tmp_df = tmp_df.rename(columns = celltype_dict)\n",
    "\n",
    "    maxloc_cellt = tmp_df.drop('cellname', axis=1).values.argmax(axis=1)\n",
    "    cell_maxct_df = pd.DataFrame()\n",
    "    cell_maxct_df['cellname'] = tmp_df['cellname']\n",
    "    cell_maxct_df['max_cell_type'] = maxloc_cellt\n",
    "\n",
    "    mismatch_df = cell_clusters[cell_maxct_df['max_cell_type'] != cell_clusters['cluster']]\n",
    "    print('num mismatched: {}'.format(cell_clusters[cell_maxct_df['max_cell_type'] != cell_clusters['cluster']].shape[0]))\n",
    "\n",
    "    figsize(4,4)\n",
    "    plt.hist(mismatch_df['cluster'])\n",
    "    plt.show()\n",
    "\n",
    "    return tmp_df, mismatch_df, cell_maxct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "cell_clusters = cell_clusters.reset_index()\n",
    "cell_clusters.columns = ['index','barcode','cluster','maxloc']\n",
    "cell_deconv_df, mismatch_dfl2, cell_maxct_df = cell_deconv(collapse='l2')\n",
    "cell_maxct_df.max_cell_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalizing deconv values (sum rows to one, i.e. the values in each bead sum to 1)\n",
    "cell_totalloading = np.sum(cell_deconv_df.drop('cellname', axis=1), axis = 1)\n",
    "cell_deconv_df_norm = np.true_divide(cell_deconv_df.drop('cellname', axis=1), cell_totalloading[:,None])\n",
    "cell_deconv_df_norm['cellname'] = cell_deconv_df['cellname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_bar_cellt(cell_deconv_df_norm, cell_maxct_df,\n",
    "                metacell_dict=metacell_dict):\n",
    "    for key, value in metacell_dict.items():\n",
    "        ct_df = cell_deconv_df_norm[cell_maxct_df['max_cell_type']==int(key)]\n",
    "        figsize(4, 4)\n",
    "        plt.bar(x=range(num_atlas_clusters),height=np.sum(ct_df.drop(['cellname'], axis=1), axis=0),\n",
    "               tick_label = list(metacell_dict.values()))\n",
    "        plt.title(value)\n",
    "        plt.xticks(rotation=90)\n",
    "        # save_result\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what proportion of beads were identified as the respective cell type in the plot\n",
    "plot_bar_cellt(cell_deconv_df_norm=cell_deconv_df_norm, cell_maxct_df=cell_maxct_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_TF(metacell_dict=metacell_dict):\n",
    "    posneg_dict = {}\n",
    "    for key, value in metacell_dict.items():\n",
    "        pos = cell_deconv_df_norm[value][cell_maxct_df['max_cell_type']==int(key)]\n",
    "        neg = cell_deconv_df_norm[value][cell_maxct_df['max_cell_type']!=int(key)]\n",
    "        posneg_dict[key] = [pos, neg]\n",
    "        figsize(4,4)\n",
    "        plt.hist(pos, range=(0,1), color='green', alpha=0.6, density=True)\n",
    "        plt.hist(neg, range=(0,1), color='red', alpha=0.6, density=True)\n",
    "        plt.title(value)\n",
    "        plt.xticks(rotation=90)\n",
    "        # save_result\n",
    "        plt.show()\n",
    "    return posneg_dict\n",
    "posneg_dict = plot_hist_TF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine the maximum value of \"negative\" cell type expression\n",
    "thresh_certainty = [0]*num_atlas_clusters\n",
    "for c in range(0, num_atlas_clusters):\n",
    "    thresh_certainty[c] = np.max(posneg_dict[c][1])\n",
    "thresh_certainty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def func_thresh_certainty(bead_deconv_df_norm, keep_thresh_df):\n",
    "    for key, value in metacell_dict.items():\n",
    "        bool_df = keep_thresh_df[int(key)]\n",
    "        ct_indx = list(bead_deconv_df_norm.index[bool_df.index])\n",
    "        bead_deconv_df_norm['thresh_ct'].ix[ct_indx] = np.multiply(bead_deconv_df_norm['maxval'].ix[ct_indx], bool_df)\n",
    "        \n",
    "    return bead_deconv_df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_size_dict = {10:4, 20:8, 40:20, 100:140}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deconv_factor_to_celltype(row, adict, K=K, nc = num_atlas_clusters):\n",
    "    tmp_list = [0]*nc\n",
    "    for key in range(K):\n",
    "        item = adict[key]\n",
    "        tmp_list[item] += row[key]**2\n",
    "    return pd.Series(np.sqrt(tmp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_certainty_thresh(coords, size, bead_deconv_df_norm,\n",
    "                plot_size_dict=plot_size_dict):\n",
    "    bool_col = bead_deconv_df_norm['thresh_ct']==0\n",
    "    figsize(12, 12)\n",
    "    plt.set_cmap('Reds')\n",
    "    plt.scatter(coords['x'], coords['y'], c=bead_deconv_df_norm['maxval'], \n",
    "                s=plot_size_dict[size], alpha=1)\n",
    "    plt.colorbar();\n",
    "    plt.scatter(coords[bool_col]['xcoord'], \n",
    "                    coords[bool_col]['ycoord'], \n",
    "                    c='lightgray', s=plot_size_dict[size], alpha=1)\n",
    "    plt.title('Purity of most prevalent cell type per bead, {}um'.format(size))\n",
    "    plt.xlabel('Single celltype beads: {}%'.format(round(100*np.divide(coords[bead_deconv_df_norm['thresh_ct']!=0].shape[0],coords.shape[0]), 2)))\n",
    "    plt.axis('equal')\n",
    "    plt.clim(0,1);\n",
    "    #save_result(\"{}ThreshCertaintyofmaxct\".format(size))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "barcode_totalloading = np.sum(bead_deconv_df.drop('barcode', axis=1), \n",
    "                                  axis = 1)\n",
    "bead_deconv_df_norm = np.true_divide(bead_deconv_df.drop('barcode', axis=1), \n",
    "                                         barcode_totalloading[:,None])\n",
    "bead_deconv_df_norm['maxval'] = bead_deconv_df_norm.apply(max, axis=1)\n",
    "bead_deconv_df_norm['barcode'] = pcounts.index.tolist()\n",
    "\n",
    "deconv_sub_df = bead_deconv_df_norm.drop('barcode', axis=1)\n",
    "bead_deconv_df_norm['max_cell_type'] = bead_maxct_df['max_cell_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bead_deconv_df_norm.max_cell_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clust = pd.DataFrame(columns=['x','y','label'])\n",
    "df_clust['x'] = coords['xcoord']\n",
    "df_clust['y'] = coords['ycoord']\n",
    "df_clust['label'] = bead_deconv_df_norm['max_cell_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clust.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plots to show how likely a bead is to be classified a given cell type\n",
    "for indx, col in deconv_sub_df.iteritems():\n",
    "    figsize(10, 10)\n",
    "    plt.set_cmap('viridis_r')\n",
    "    plt.scatter(coords['xcoord'], coords['ycoord'], c=bead_deconv_df_norm[indx], \n",
    "                    s=1, alpha=0.6)\n",
    "    plt.title('cluster {0} DKD'.format(indx,tissue_status),fontsize=35)\n",
    "    plt.axis('equal')\n",
    "    plt.rc('xtick', labelsize=15)     \n",
    "    plt.rc('ytick', labelsize=15)\n",
    "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "    plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    plt.colorbar();\n",
    "    plt.clim(0,1);\n",
    "    #save_result(\"{}loading{}\".format(size, indx))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxval_func(row): return row[bead_deconv_df_norm[str(row['max_cell_type'])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_boolean_thresh(size, coords, bead_maxct_df, bead_deconv_df_norm,\n",
    "                 plot_size_dict=plot_size_dict,\n",
    "                 metacell_dict=metacell_dict):\n",
    "    bool_col = bead_deconv_df_norm['thresh_ct']==0\n",
    "    print(bool_col)\n",
    "    for key, value in metacell_dict.items():\n",
    "        boolcol = bead_maxct_df['max_cell_type']==int(key)\n",
    "        sub_df = bead_maxct_df.copy()\n",
    "        sub_df['bool'] = boolcol\n",
    "        bool_col_ct = np.multiply(bool_col, boolcol)\n",
    "        print(bool_col_ct)\n",
    "\n",
    "        figsize(12, 12)\n",
    "        plt.set_cmap('copper_r')\n",
    "        plt.scatter(coords['xcoord'], coords['ycoord'], c=sub_df['bool'], s=plot_size_dict[size], alpha=0.6)\n",
    "        plt.scatter(coords[bool_col_ct]['xcoord'], \n",
    "                    coords[bool_col_ct]['ycoord'], \n",
    "                    c='lightgray', s=plot_size_dict[size], alpha=1)\n",
    "        plt.title('{} {}um'.format(value, size))\n",
    "        plt.axis('equal')\n",
    "        #save_result(\"{}boolean_thresh{}\".format(size, value))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_certainty_perct_thresh(coords, size, bead_deconv_df_norm, df_clust, bead_maxct_df,\n",
    "                plot_size_dict=plot_size_dict):\n",
    "    keep_thresh_df = {}\n",
    "    remove_thresh_df = {}\n",
    "    bead_deconv_df_norm['max_cell_type'] = bead_maxct_df['max_cell_type']\n",
    "    \n",
    "    for key, value in metacell_dict.items():\n",
    "        bool_col = df_clust['label']==int(key)\n",
    "        ct_df = bead_deconv_df_norm[bool_col]\n",
    "        ct_df['col'] = ct_df['maxval'].apply(lambda x: 0 if x <= thresh_certainty[int(key)-1] else x)\n",
    "        keep_thresh_df[int(key)-1] = ct_df['maxval'] > thresh_certainty[int(key)-1]\n",
    "        remove_thresh_df[int(key)-1] = ct_df['maxval'] <= thresh_certainty[int(key)-1]\n",
    "        \n",
    "        figsize(12, 12)\n",
    "        plt.set_cmap('Reds')\n",
    "        plt.scatter(df_clust['x'], df_clust['y'], c='white', \n",
    "                    edgecolors='gray', linewidths=0.25, \n",
    "                    s=plot_size_dict[size], alpha=0.6)\n",
    "        plt.scatter(coords[bool_col]['xcoord'], coords[bool_col]['ycoord'], \n",
    "                    c=ct_df['col'], s=plot_size_dict[size], alpha=0.9)\n",
    "        plt.colorbar();\n",
    "        plt.scatter(coords[bool_col]['xcoord'][ct_df['col']==0], \n",
    "                    coords[bool_col]['ycoord'][ct_df['col']==0], \n",
    "                    c='gray', s=plot_size_dict[size], alpha=0.4)\n",
    "        \n",
    "        plt.title('Purity of {} per bead, {}um'.format(value, size))\n",
    "        plt.axis('equal')\n",
    "        plt.clim(0,1);\n",
    "        #save_result(\"{}ThreshCertaintyofmaxct{}\".format(size, value))\n",
    "        plt.show()\n",
    "        \n",
    "    return keep_thresh_df, remove_thresh_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def func_thresh_certainty(bead_deconv_df_norm, keep_thresh_df):\n",
    "    for key, value in metacell_dict.items():\n",
    "        bool_df = keep_thresh_df[int(key)-1]\n",
    "        ct_indx = list(bead_deconv_df_norm.index[bool_df.index])\n",
    "        bead_deconv_df_norm['thresh_ct'].ix[ct_indx] = np.multiply(bead_deconv_df_norm['maxval'].ix[ct_indx], bool_df)\n",
    "        \n",
    "    return bead_deconv_df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_allct(coords, size, bead_deconv_df_norm, bead_maxct_df,\n",
    "                plot_size_dict=plot_size_dict):\n",
    "    bead_deconv_df_norm['max_cell_type'] = bead_maxct_df['max_cell_type']\n",
    "\n",
    "    df_clust = pd.DataFrame(columns=['x','y','label'])\n",
    "    df_clust['x'] = coords['xcoord']\n",
    "    df_clust['y'] = coords['ycoord']\n",
    "    df_clust['label'] = bead_deconv_df_norm['max_cell_type']\n",
    "\n",
    "    facet = sns.lmplot(data=df_clust, x='x', y='y', hue='label', \n",
    "                       fit_reg=False, legend=False, legend_out=True,\n",
    "                       palette = sns.color_palette(\"tab20\", int(num_atlas_clusters)),\n",
    "                       size = 10, scatter_kws={\"s\": 2*plot_size_dict[size]})\n",
    "    #add a legend\n",
    "    leg = facet.ax.legend(bbox_to_anchor=[1, 0.75],\n",
    "                             title=\"label\", fancybox=True)\n",
    "    #change colors of labels\n",
    "    for i, text in enumerate(leg.get_texts()):\n",
    "        plt.setp(text, color = sns.color_palette(\"tab20\", int(num_atlas_clusters))[i])\n",
    "    #save_result(\"{}all_celltypes\".format(size))\n",
    "    plt.show()\n",
    "    return df_clust, bead_deconv_df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clust.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in metacell_dict.items():\n",
    "    bool_col = (df_clust['label']==int(key))\n",
    "    print(bool_col)\n",
    "    ct_df = bead_deconv_df_norm[bool_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clust.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_df, remove_thresh_df = plot_certainty_perct_thresh(coords=coords, size=10, bead_deconv_df_norm=bead_deconv_df_norm, df_clust=df_clust, bead_maxct_df = bead_maxct_df)\n",
    "\n",
    "#need more memory for this (only outputted 17 plots)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bead_deconv_df_norm['thresh_ct'] = bead_deconv_df_norm['maxval']\n",
    "bead_deconv_df_norm = func_thresh_certainty(bead_deconv_df_norm=bead_deconv_df_norm, \n",
    "                                         keep_thresh_df=keep_thresh_df)\n",
    "\n",
    "plot_boolean_thresh(size=10, coords=coords, bead_maxct_df=bead_maxct_df,bead_deconv_df_norm=bead_deconv_df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clust, bead_deconv_df_norm = plot_allct(coords=coords, size=10, \n",
    "                bead_deconv_df_norm=bead_deconv_df_norm, \n",
    "                bead_maxct_df=bead_maxct_df)\n",
    "                                           \n",
    "                        \n",
    "df_clust.to_csv(\"{}/df_clust10.csv\".format(NMFreg_output), index=False)\n",
    "bead_deconv_df_norm.to_csv(\"{}/bead_deconv_df_norm.csv\".format(NMFreg_output), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genes=pcounts.columns.tolist()\n",
    "pcounts_scaled_df=pd.DataFrame(pcounts_scaled)\n",
    "pcounts_scaled_df.set_axis(genes, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates csv files for future use by plotting/analysis pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creates csv for permutation test methods\n",
    "pcounts_perm_test=pd.DataFrame(pcounts_scaled_df)\n",
    "pcounts_perm_test['xcoord']=df_clust['x']\n",
    "pcounts_perm_test['ycoord']=df_clust['y']\n",
    "pcounts_perm_test['cluster']=df_clust['label']\n",
    "\n",
    "f1 = Perm_test_output + pkn + \".csv\"\n",
    "pcounts_perm_test.to_csv(f1, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creates csv for interactive plotting  \n",
    "pcounts_webpage=pd.DataFrame(pcounts_scaled_df)\n",
    "pcounts_webpage['xcoord']=coords['xcoord']\n",
    "pcounts_webpage['ycoord']=coords['ycoord']\n",
    "\n",
    "f1 = Interactive_plot_output + pkn + \"_webpage_data.csv\"\n",
    "pcounts_webpage.to_csv(f1, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot single genes from your sample\n",
    "def plot_one_gene(gene):\n",
    "    figsize(13, 10)\n",
    "    pyplot.set_cmap('viridis_r')\n",
    "    #plt.scatter(coords['xcoord'], coords['ycoord'], c=pcounts[gene], s=2, alpha=0.6)\n",
    "    #testing something\n",
    "    plt.scatter(coords['xcoord'], coords['ycoord'], c=pcounts_scaled_df[gene], s=2, alpha=0.6)\n",
    "    # BREANNA: other version uses \"counts\" instead of pcounts\n",
    "    plt.axis('equal')\n",
    "    plt.title('{}'.format(gene),fontsize=35)\n",
    "    plt.rc('xtick', labelsize=10)     \n",
    "    plt.rc('ytick', labelsize=10)\n",
    "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0,0))\n",
    "    plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    plt.colorbar();\n",
    "    #plt.clim(0,12)\n",
    "    #save_result(gene)\n",
    "    plt.savefig(\"test.svg\",format=\"svg\")\n",
    "    plt.show()\n",
    "    \n",
    "#interesting_genes = ['Aqp5']\n",
    "#interesting_genes = ['Ociad2']\n",
    "interesting_genes = ['Aqp1', 'Aqp2', 'Aqp6', 'Atp11a', 'Atp6vo1b2', 'Bst2', 'C1qa', 'C1qb',\n",
    "       'Ccl11', 'Ccl17', 'Ccl2', 'Ccl20', 'Ccl22', 'Ccl3', 'Ccl4', 'Ccl5',\n",
    "       'Ccr7', 'Cd40', 'Cd80', 'Cd86', 'Ctgf', 'Cxcl1', 'Cxcl10', 'Cxcl11',\n",
    "       'Cxcl13', 'Cxcl5', 'Cxcl9', 'Ehd3', 'Enpp2', 'GAPDH', 'GFP',\n",
    "       'Gapdh_mouse', 'H2-Ab1', 'H2-Eb1', 'Ifitm3', 'Ifnb1', 'Il10', 'Il12a',\n",
    "       'Il12b', 'Il13', 'Il17', 'Il1a', 'Il1b', 'Il2', 'Il4', 'Il6', 'Il8',\n",
    "       'Il9', 'Isg15', 'Itga8', 'KDR', 'LRP2', 'Miox', 'Muc1', 'Mx1', 'Mx2',\n",
    "       'NM_009735_B2m', 'NM_013556_Hprt', 'Napsa', 'Nphs2', 'Oasl1', 'Pecam1',\n",
    "       'Plvap', 'Ptn', 'Rpl13a', 'Rps29', 'Rsad2', 'Slc12a1', 'Slc22a7',\n",
    "       'Slc34a1', 'Synpo', 'Tnf', 'Tnfaip3', 'UMOD', 'Wt1']\n",
    "\n",
    "plot_one_gene(gene='Aqp1')\n",
    "\n",
    "#for g in interesting_genes:\n",
    "    #if g in pcounts.columns:# BREANNA: this conditional statement not present in other version\n",
    "        #print(g) # BREANNA: no print statement in other version\n",
    "        #plot_one_gene(gene=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#barcode vs original cell name.... where?\n",
    "coords.barcode.str.contains(\"Puck\").sum() #... no??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords.barcode.str.contains(\"\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #ok everything here is for DKD -> output them, so that we can later compare\n",
    "# #beads_deconv for cluster assignment\n",
    "# #coords for coordinates\n",
    "# #pcount for individual cell inspection\n",
    "# pkn = \"Puck_181206_3\"\n",
    "# #mydir = \"/broad/finucanelab/qingbow/slseq/sumdata/\"\n",
    "# # Breanna changed for her directory\n",
    "# mydir=\"/broad/thechenlab/breanna/breanna_slideseq_sumdata/\"\n",
    "# f1 = mydir + pkn + \"coords.tsv\"\n",
    "# f2 = mydir + pkn + \"pcount.tsv\"\n",
    "# f3 = mydir + pkn + \"bead_deconv_df_norm.tsv\"\n",
    "# coords.to_csv(f1, index=True)\n",
    "# print (\"1 done\")\n",
    "# pcounts.to_csv(f2, index=True)\n",
    "# print (\"2 done\")\n",
    "# bead_deconv_df_norm.to_csv(f3, index=True)\n",
    "# print (\"3 done\")\n",
    "\n",
    "# #OK move to the wt and do the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_df10, remove_thresh_df10 = plot_certainty_perct_thresh(coords=coords, \n",
    "                                          size=10, \n",
    "                                          bead_deconv_df_norm=bead_deconv_df_norm, \n",
    "                                          df_clust=df_clust,\n",
    "                                          bead_maxct_df=bead_maxct_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
